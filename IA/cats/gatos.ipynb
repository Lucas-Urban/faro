{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe das bibliotecas necessárias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do caminho para o diretório do seu conjunto de dados\n",
    "dataset_path = \"C://Users//Pichau//Documents//GitHub//faro//IA//cats//images\"\n",
    "\n",
    "# Configuração do tamanho desejado para as imagens\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2692 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criação dos geradores de dados para treinamento\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 666 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "# Criação dos geradores de dados para validação\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# Carregamento da base MobileNetV2 pré-treinada, excluindo a camada superior\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "# Adição de novas camadas para a classificação\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Experimente diferentes taxas de dropout\n",
    "\n",
    "num_classes = 22\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Criação do modelo final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congela as camadas do MobileNetV2 para que elas não sejam treinadas novamente\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Ajuste da taxa de aprendizado\n",
    "custom_optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 96s 1s/step - loss: 2.4599 - accuracy: 0.2992 - val_loss: 1.5319 - val_accuracy: 0.6109\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 67s 802ms/step - loss: 1.4624 - accuracy: 0.5688 - val_loss: 0.9923 - val_accuracy: 0.7344\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 68s 807ms/step - loss: 1.0956 - accuracy: 0.6564 - val_loss: 0.8341 - val_accuracy: 0.7359\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 64s 766ms/step - loss: 0.9176 - accuracy: 0.7105 - val_loss: 0.7133 - val_accuracy: 0.7656\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.7951 - accuracy: 0.7451 - val_loss: 0.6816 - val_accuracy: 0.7922\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 64s 759ms/step - loss: 0.7185 - accuracy: 0.7718 - val_loss: 0.6090 - val_accuracy: 0.8078\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 63s 753ms/step - loss: 0.6491 - accuracy: 0.7895 - val_loss: 0.5859 - val_accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 64s 761ms/step - loss: 0.6145 - accuracy: 0.8000 - val_loss: 0.5924 - val_accuracy: 0.8031\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.5568 - accuracy: 0.8222 - val_loss: 0.5553 - val_accuracy: 0.8047\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 64s 756ms/step - loss: 0.5250 - accuracy: 0.8252 - val_loss: 0.5385 - val_accuracy: 0.8156\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 64s 761ms/step - loss: 0.5067 - accuracy: 0.8365 - val_loss: 0.5185 - val_accuracy: 0.8234\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 64s 755ms/step - loss: 0.4764 - accuracy: 0.8414 - val_loss: 0.5339 - val_accuracy: 0.8062\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 64s 759ms/step - loss: 0.4487 - accuracy: 0.8481 - val_loss: 0.5265 - val_accuracy: 0.8125\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.4440 - accuracy: 0.8545 - val_loss: 0.5332 - val_accuracy: 0.8109\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 65s 768ms/step - loss: 0.3957 - accuracy: 0.8772 - val_loss: 0.4963 - val_accuracy: 0.8094\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 64s 756ms/step - loss: 0.3843 - accuracy: 0.8805 - val_loss: 0.4671 - val_accuracy: 0.8219\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 64s 764ms/step - loss: 0.3652 - accuracy: 0.8850 - val_loss: 0.5025 - val_accuracy: 0.8250\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 64s 755ms/step - loss: 0.3507 - accuracy: 0.8895 - val_loss: 0.4811 - val_accuracy: 0.8469\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 64s 761ms/step - loss: 0.3261 - accuracy: 0.8974 - val_loss: 0.4637 - val_accuracy: 0.8484\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 63s 748ms/step - loss: 0.3297 - accuracy: 0.8947 - val_loss: 0.4718 - val_accuracy: 0.8375\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 63s 752ms/step - loss: 0.2858 - accuracy: 0.9158 - val_loss: 0.4953 - val_accuracy: 0.8094\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 63s 750ms/step - loss: 0.2956 - accuracy: 0.9049 - val_loss: 0.4825 - val_accuracy: 0.8219\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 63s 753ms/step - loss: 0.2905 - accuracy: 0.9068 - val_loss: 0.5062 - val_accuracy: 0.8203\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 63s 761ms/step - loss: 0.2718 - accuracy: 0.9180 - val_loss: 0.4816 - val_accuracy: 0.8344\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 63s 752ms/step - loss: 0.2475 - accuracy: 0.9256 - val_loss: 0.4971 - val_accuracy: 0.8109\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 63s 752ms/step - loss: 0.2454 - accuracy: 0.9305 - val_loss: 0.5186 - val_accuracy: 0.8109\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 63s 753ms/step - loss: 0.2366 - accuracy: 0.9323 - val_loss: 0.4872 - val_accuracy: 0.8297\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 63s 751ms/step - loss: 0.2251 - accuracy: 0.9383 - val_loss: 0.4792 - val_accuracy: 0.8391\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 63s 752ms/step - loss: 0.2275 - accuracy: 0.9305 - val_loss: 0.4960 - val_accuracy: 0.8313\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 64s 758ms/step - loss: 0.2150 - accuracy: 0.9368 - val_loss: 0.4804 - val_accuracy: 0.8266\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 64s 755ms/step - loss: 0.1998 - accuracy: 0.9444 - val_loss: 0.5030 - val_accuracy: 0.8297\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 63s 754ms/step - loss: 0.2039 - accuracy: 0.9372 - val_loss: 0.4873 - val_accuracy: 0.8203\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 64s 763ms/step - loss: 0.1926 - accuracy: 0.9436 - val_loss: 0.5116 - val_accuracy: 0.8172\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 64s 763ms/step - loss: 0.1938 - accuracy: 0.9429 - val_loss: 0.4944 - val_accuracy: 0.8078\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 82s 980ms/step - loss: 0.1954 - accuracy: 0.9425 - val_loss: 0.4714 - val_accuracy: 0.8375\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 76s 899ms/step - loss: 0.1834 - accuracy: 0.9477 - val_loss: 0.5413 - val_accuracy: 0.8203\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 75s 897ms/step - loss: 0.1678 - accuracy: 0.9549 - val_loss: 0.4791 - val_accuracy: 0.8344\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 76s 904ms/step - loss: 0.1798 - accuracy: 0.9477 - val_loss: 0.4452 - val_accuracy: 0.8438\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 74s 893ms/step - loss: 0.1643 - accuracy: 0.9481 - val_loss: 0.4900 - val_accuracy: 0.8297\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 75s 889ms/step - loss: 0.1602 - accuracy: 0.9556 - val_loss: 0.4743 - val_accuracy: 0.8250\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 75s 892ms/step - loss: 0.1452 - accuracy: 0.9579 - val_loss: 0.5042 - val_accuracy: 0.8109\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 71s 849ms/step - loss: 0.1471 - accuracy: 0.9575 - val_loss: 0.5266 - val_accuracy: 0.8156\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 74s 877ms/step - loss: 0.1429 - accuracy: 0.9620 - val_loss: 0.4913 - val_accuracy: 0.8266\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 71s 841ms/step - loss: 0.1416 - accuracy: 0.9643 - val_loss: 0.4836 - val_accuracy: 0.8297\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 75s 898ms/step - loss: 0.1250 - accuracy: 0.9684 - val_loss: 0.4815 - val_accuracy: 0.8313\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 76s 898ms/step - loss: 0.1408 - accuracy: 0.9575 - val_loss: 0.4687 - val_accuracy: 0.8281\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 69s 816ms/step - loss: 0.1207 - accuracy: 0.9711 - val_loss: 0.4553 - val_accuracy: 0.8484\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 66s 781ms/step - loss: 0.1237 - accuracy: 0.9665 - val_loss: 0.4779 - val_accuracy: 0.8344\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 66s 784ms/step - loss: 0.1243 - accuracy: 0.9632 - val_loss: 0.4904 - val_accuracy: 0.8328\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 66s 789ms/step - loss: 0.1125 - accuracy: 0.9726 - val_loss: 0.4741 - val_accuracy: 0.8188\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=60,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Salvamento do modelo treinado\n",
    "model.save('cat_breed_classifier.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
